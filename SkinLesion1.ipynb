{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkinLesion1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzjc9rfAN75d"
      },
      "source": [
        "#Skin Cancer Detector\n",
        "\n",
        "O projeto conta com a criação de uma rede neural capaz de realizar o aprendizado de máquina e reconhecimento de padrões para identificar e classificar uma imagem de lesão de pele baseado em 7 principais tipos:\n",
        "- Nevo melanocítico: Distúrbio geralmente não cancerígeno das células da pele produtoras de pigmento, comumente chamado de marcas de nascença ou pintas.\n",
        "- Melanoma: O tipo mais grave de câncer de pele. O melanoma ocorre quando as células produtoras dos pigmentos que dão cor à pele tornam-se cancerígenas.\n",
        "- Verruga seborreica: Condição de pele benigna com aspecto de um nódulo maleável de cor castanha, preta ou marrom.\n",
        "A ceratose seborreica é um dos tumores de pele benignos mais comuns em idosos. Embora existam casos de tumores individuais, a presença de vários tumores é mais comum.\n",
        "-  Carcinoma basocelular: Tipo de câncer de pele que começa nas células basais.\n",
        "As células basais produzem novas células da pele conforme as antigas morrem. Limitar a exposição ao sol pode ajudar a evitar que essas células se tornem cancerígenas.\n",
        "Esse tipo de câncer geralmente aparece como um nódulo de cera branco ou uma mancha escamosa marrom em áreas expostas ao sol, como rosto e pescoço.\n",
        "-  Ceratose actínica: Mancha escamosa áspera na pele causada por anos de exposição ao sol.\n",
        "A ceratose actínica geralmente afeta idosos. Reduzir a exposição ao sol pode ajudar a diminuir o risco.\n",
        "É mais comum no rosto, nos lábios, nas orelhas, no dorso das mãos, nos antebraços, no couro cabeludo e no pescoço. A pele escamosa e áspera aumenta lentamente e não costuma causar outros sinais ou sintomas. A lesão pode levar anos para se desenvolver.\n",
        "-  Lesões vasculares: As anomalias vasculares correspondem a um extenso espectro de alterações que se dividem em dois grupos principais: 1) tumores vasculares, que representam as lesões proliferativas e 2) malformações vasculares, originadas por ectasias nos vasos, sejam elas capilares, venosas ou linfáticas.\n",
        "-  Dermatofibroma: lesões benignas típicas de extremidades, como braços, antebraços e pernas. Por terem coloração acastanhada, geralmente, são motivos de consulta, na qual os pacientes buscam saber se são pintas ou sinais.\n",
        "\n",
        "Realizando com precisão a classificação será possível então direcionar o melhor tratamento possível."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCgUjrEhOQeE"
      },
      "source": [
        "Começamos o projeto importanto a base de dados das imagens que estavam alocadas no drive do trabalho."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsXhTQtIBOJq",
        "outputId": "f8515681-bddb-4d26-805e-4592eede6fcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86sUc-s1OhXW"
      },
      "source": [
        "Importamos todas as bibliotecas que serão necessárias ao longo do desenvolvimento da nossa rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LQWlyQ1MYx6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyY73Z_tOz4Y"
      },
      "source": [
        "Abrimos o arquivo que continha a classificação para cada imagem do dataset de treino e dataset de validação. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FoimGh9_tI5n",
        "outputId": "27ebdad8-58ed-4a15-d150-81c24c9face0"
      },
      "source": [
        "metadata = pd.read_csv('/content/drive/My Drive/TEES/Trabalho/HAM10000_metadata')\n",
        "metadata_validation = pd.read_csv('/content/drive/My Drive/TEES/Trabalho/metadata_validation.csv')\n",
        "\n",
        "metadata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ...   sex  localization       dataset\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...  male         scalp  vidir_modern\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...  male         scalp  vidir_modern\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...  male         scalp  vidir_modern\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...  male         scalp  vidir_modern\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...  male           ear  vidir_modern\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRS4oBt3RmH2"
      },
      "source": [
        "metadata_validation.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eIN_UqiQAMj"
      },
      "source": [
        "Agrupamos as imagens do dataset que estava fragmentado em duas pastas por conta do tamanho e quantidade em apenas uma pasta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjpplPRytitT"
      },
      "source": [
        "# It's not necessary to run this cell again\n",
        "old_path1 = '/content/drive/My Drive/TEES/Trabalho/HAM10000_part_2/'\n",
        "new_path1 = '/content/drive/My Drive/TEES/Trabalho/HAM10000_part_1/'\n",
        "archives = os.listdir(old_path1)\n",
        "for i in archives:\n",
        "  os.replace((old_path1+i), (new_path1+i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQwS7wXTQcxL"
      },
      "source": [
        "Checando a quantidade de imagens da pasta original e da pasta de destino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "RMxBpZMODRnd",
        "outputId": "c4bc58f3-1b7b-4c10-c344-e7a0dde93743"
      },
      "source": [
        "# Number of images in the folders\n",
        "print(len(os.listdir(old_path1)))\n",
        "print(len(os.listdir(new_path1))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e6ee45d5d5bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Number of images in the folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_path1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qb9sozZQlC_"
      },
      "source": [
        "Organizando as imagens em pastas representando suas classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtA7a3atX3j"
      },
      "source": [
        "# Organizing the images in folders representing their classes\n",
        "# It's not necessary to run this cell again\n",
        "\n",
        "old_path_2 = '/content/drive/My Drive/TEES/Trabalho/HAM10000_part_1/'\n",
        "new_path_2 = '/content/drive/My Drive/TEES/Trabalho/dataset/'\n",
        "\n",
        "for i in range(0, len(metadata)):\n",
        "  os.replace(old_path_2+metadata.image_id[i]+'.jpg', new_path_2+metadata.dx[i]+\"/\"+metadata.image_id[i]+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVW_7VC0Q2oE"
      },
      "source": [
        "Aqui podemos verificar a quantidade de imagens para cada tipo de lesão de pele"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwmZ_sAavdam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7134df37-7100-4600-9832-8eba68b48c2e"
      },
      "source": [
        "print(len(os.listdir(old_path_2)))\n",
        "print(len(os.listdir(new_path_2+'akiec')))\n",
        "print(len(os.listdir(new_path_2+'bcc')))\n",
        "print(len(os.listdir(new_path_2+'bkl')))\n",
        "print(len(os.listdir(new_path_2+'df')))\n",
        "print(len(os.listdir(new_path_2+'mel')))\n",
        "print(len(os.listdir(new_path_2+'nv')))\n",
        "print(len(os.listdir(new_path_2+'vasc')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "327\n",
            "514\n",
            "1099\n",
            "115\n",
            "1113\n",
            "6721\n",
            "142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofIvl6dXSBr6"
      },
      "source": [
        "Organizando o dataset de validação em novas pastas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RenJ3WLox3FA"
      },
      "source": [
        "# Now organizing the validation dataset\n",
        "#It's not necessary to run this cell again\n",
        "path3 = '/content/drive/My Drive/TEES/Trabalho/dataset_validation/'\n",
        "\n",
        "for i in range(0, len(metadata_validation)):\n",
        "  if metadata_validation.MEL[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'mel/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.NV[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'nv/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.BCC[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'bcc/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.AKIEC[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'akiec/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.BKL[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'bkl/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.DF[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'df/'+metadata_validation.image[i]+'.jpg')\n",
        "  elif metadata_validation.VASC[i] == 1.0:\n",
        "    os.replace((path3+metadata_validation.image[i]+'.jpg'), path3+'vasc/'+metadata_validation.image[i]+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xh6TSg6SWTk"
      },
      "source": [
        "Listando a quantidade de imagens de cada tipo de lesão de pele no dataset de validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-An6QUUB-9cl",
        "outputId": "75371921-7b6c-48e1-cd9b-2da6e95416df"
      },
      "source": [
        "print(len(os.listdir(path3+'akiec')))\n",
        "print(len(os.listdir(path3+'bcc')))\n",
        "print(len(os.listdir(path3+'bcc')))\n",
        "print(len(os.listdir(path3+'df')))\n",
        "print(len(os.listdir(path3+'mel')))\n",
        "print(len(os.listdir(path3+'nv')))\n",
        "print(len(os.listdir(path3+'vasc')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "15\n",
            "22\n",
            "1\n",
            "22\n",
            "122\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISj9G2wGNY3v",
        "outputId": "e7fc9773-efaa-49ca-f5ee-8f62a7d29631"
      },
      "source": [
        "def testar_gpu():\n",
        "\ttrain_on_gpu = torch.cuda.is_available() #Observa se a GPU está disponivel\n",
        "\tif train_on_gpu: #Se sim\n",
        "\t\tdevice = torch.device('cuda') #Seleciona o device como GPU\n",
        "\t\tprint(\"Treinando na GPU\") #E manda a mensagem\n",
        "\telse: #Se não\n",
        "\t\tdevice = torch.device('cpu') #Seleciona o device como cpu\n",
        "\t\tprint(\"GPU indisponível, treinando na CPU\") #E avisa que a GPU não esta disponível\n",
        "\treturn device\n",
        "\n",
        "device = testar_gpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando na GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tpIZk4hNi2Q",
        "outputId": "05fc3a67-dbbb-4cef-c94f-e9c459272acf"
      },
      "source": [
        "# transform = transforms.Compose([\n",
        "#                                 transforms.RandomHorizontalFlip(),\n",
        "#                                 transforms.RandomRotation(10),\n",
        "#                                 transforms.Resize((255, 255)),\n",
        "#                                 transforms.ToTensor(),\n",
        "#                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#                               ])\n",
        "# data = ImageFolder('/content/drive/My Drive/TEES/Trabalho/dataset/', transform=transform)\n",
        "# print('Total de imagens no dataset: ', len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens no dataset:  10015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaqYLyvySqQZ"
      },
      "source": [
        "Utilizando o *ImageDataGenerator* realizamos alteração de tamanho, zoom, direção e distorção do ângulo de algumas imagens do nosso dataset para generalizar as imagens e abranger um número maior de possibilidades de imagens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhfgG3j2k2_S",
        "outputId": "6ac7aa7f-0f68-47ee-b6b5-39eb99a96224"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10031 images belonging to 7 classes.\n",
            "Found 193 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz_6ZrgDUqdK"
      },
      "source": [
        "Definimos o tamanho padrão das imagens e agrupamos, dividimos em grupos e aplicamos a transformação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z_5KfHuS_9a"
      },
      "source": [
        "data = datagen.flow_from_directory('/content/drive/My Drive/TEES/Trabalho/dataset/',\n",
        "                                                 target_size = (255, 255),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "data_val = datagen.flow_from_directory('/content/drive/My Drive/TEES/Trabalho/dataset_validation/',\n",
        "                                                 target_size = (255, 255),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_tPL0Y4l5Yc9",
        "outputId": "4ca5e3e7-9302-44d0-eca2-ca1e06bc72c8"
      },
      "source": [
        "# dataVis = ImageList.from_folder('/content/drive/My Drive/TEES/Trabalho/dataset/')\n",
        "# dataVis.open(dataVis.items[randint(0,len(dataVis))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2b2ba26f8585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataVis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/TEES/Trabalho/dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataVis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataVis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataVis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageList' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu14wRL1pl4-"
      },
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOun-DZljqoK"
      },
      "source": [
        "# labels = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "# for i in range (0, len(metadata.dx)):\n",
        "#   if metadata.dx[i] == 'akiec':\n",
        "#     metadata.dx[i] = 0\n",
        "#   elif metadata.dx[i] == 'bcc':\n",
        "#     metadata.dx[i] = 1\n",
        "#   elif metadata.dx[i] == 'bkl':\n",
        "#     metadata.dx[i] = 2\n",
        "#   elif metadata.dx[i] == 'df':\n",
        "#     metadata.dx[i] = 3\n",
        "#   elif metadata.dx[i] == 'mel':\n",
        "#     metadata.dx[i] = 4\n",
        "#   elif metadata.dx[i] == 'nv':\n",
        "#     metadata.dx[i] = 5\n",
        "#   elif metadata.dx[i] == 'vasc':\n",
        "#     metadata.dx[i] = 6\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "Qe9jE1gGtTYV",
        "outputId": "da1edfb3-297c-44ef-cc48-490978bfba49"
      },
      "source": [
        "# # y = metadata.dx.to_numpy(dtype = int)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data, test_size = 0.3, random_state = 0)\n",
        "\n",
        "# print('Total de imagens no dataset de treino:', len(X_train))\n",
        "# print('Total de imagens no dataset de teste:', len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2f3d4e656428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# y = metadata.dx.to_numpy(dtype = int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total de imagens no dataset de treino:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total de imagens no dataset de teste:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIUphyzSBDa0",
        "outputId": "81254aae-cede-4e05-953d-6a689a6ce6ee"
      },
      "source": [
        "# y = tf.convert_to_tensor(y)\n",
        "# type(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "JiDqIi_S3ZPP",
        "outputId": "8f5fa9c5-e63c-40fa-db55-535edcf6c074"
      },
      "source": [
        "# for i in range (0, len(X_train)):\n",
        "#   if i < len(X_test):\n",
        "#     X_train[i] = np.array(X_train)\n",
        "#     X_train[i] = tf.convert_to_tensor(X_train[i])\n",
        "#     X_test[i] = np.array(X_train)\n",
        "#     X_test[i] = tf.convert_to_tensor\n",
        "#   else:\n",
        "#     X_train[i] = np.array(X_train)\n",
        "#     X_train[i] = tf.convert_to_tensor(X_train[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-10ebafae0dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJJxA0WCVcVu"
      },
      "source": [
        "Definimos a rede neural com duas camadas de convolução com ativação *relu* e duas camadas de *MaxPooling*, planificamos os dados e adicionamos uma camada *Dense* com ativação *relu* e outra camada *Dense* com ativação *Sigmoid* que será a saida da rede.\n",
        "\n",
        "A escolha da saida em *sigmoid* se deve ao fato de sua saída ser sempre em porcentagem, variando de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCpG2y_b02b6"
      },
      "source": [
        "cnn = tf.keras.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[255, 255, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSUYIl3TXp6Y"
      },
      "source": [
        "Compilamos a rede neural, definindo o ativador, a função de perda e a métrica a ser avaliada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJSeyYqNAlQP"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh_B4OeiX9Hu"
      },
      "source": [
        "Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-mNTcAsAl_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd57ccc0-6e30-4667-b548-3244a1fa8fe9"
      },
      "source": [
        "cnn.fit(x = data, validation_data = data_val, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "314/314 [==============================] - 2047s 6s/step - loss: 0.2547 - accuracy: 0.6661 - val_loss: 0.2198 - val_accuracy: 0.6269\n",
            "Epoch 2/25\n",
            "314/314 [==============================] - 269s 856ms/step - loss: 0.2201 - accuracy: 0.6749 - val_loss: 0.2068 - val_accuracy: 0.6321\n",
            "Epoch 3/25\n",
            "314/314 [==============================] - 267s 850ms/step - loss: 0.2121 - accuracy: 0.6820 - val_loss: 0.1921 - val_accuracy: 0.7047\n",
            "Epoch 4/25\n",
            "314/314 [==============================] - 268s 853ms/step - loss: 0.2023 - accuracy: 0.6895 - val_loss: 0.1881 - val_accuracy: 0.6943\n",
            "Epoch 5/25\n",
            "314/314 [==============================] - 267s 851ms/step - loss: 0.1914 - accuracy: 0.6994 - val_loss: 0.1800 - val_accuracy: 0.7150\n",
            "Epoch 6/25\n",
            "314/314 [==============================] - 267s 849ms/step - loss: 0.1892 - accuracy: 0.7034 - val_loss: 0.1822 - val_accuracy: 0.7150\n",
            "Epoch 7/25\n",
            "314/314 [==============================] - 266s 848ms/step - loss: 0.1839 - accuracy: 0.7107 - val_loss: 0.1817 - val_accuracy: 0.6943\n",
            "Epoch 8/25\n",
            "314/314 [==============================] - 264s 839ms/step - loss: 0.1826 - accuracy: 0.7153 - val_loss: 0.1656 - val_accuracy: 0.7617\n",
            "Epoch 9/25\n",
            "314/314 [==============================] - 264s 842ms/step - loss: 0.1794 - accuracy: 0.7190 - val_loss: 0.1650 - val_accuracy: 0.6995\n",
            "Epoch 10/25\n",
            "314/314 [==============================] - 273s 869ms/step - loss: 0.1787 - accuracy: 0.7215 - val_loss: 0.1617 - val_accuracy: 0.7306\n",
            "Epoch 11/25\n",
            "314/314 [==============================] - 281s 894ms/step - loss: 0.1752 - accuracy: 0.7252 - val_loss: 0.1588 - val_accuracy: 0.7409\n",
            "Epoch 12/25\n",
            "314/314 [==============================] - 274s 874ms/step - loss: 0.1732 - accuracy: 0.7275 - val_loss: 0.1739 - val_accuracy: 0.7202\n",
            "Epoch 13/25\n",
            "314/314 [==============================] - 274s 874ms/step - loss: 0.1712 - accuracy: 0.7298 - val_loss: 0.1529 - val_accuracy: 0.7254\n",
            "Epoch 14/25\n",
            "314/314 [==============================] - 269s 857ms/step - loss: 0.1675 - accuracy: 0.7384 - val_loss: 0.1587 - val_accuracy: 0.7358\n",
            "Epoch 15/25\n",
            "314/314 [==============================] - 272s 865ms/step - loss: 0.1681 - accuracy: 0.7411 - val_loss: 0.1608 - val_accuracy: 0.7513\n",
            "Epoch 16/25\n",
            "314/314 [==============================] - 270s 859ms/step - loss: 0.1649 - accuracy: 0.7460 - val_loss: 0.1471 - val_accuracy: 0.7461\n",
            "Epoch 17/25\n",
            "314/314 [==============================] - 267s 851ms/step - loss: 0.1626 - accuracy: 0.7529 - val_loss: 0.1582 - val_accuracy: 0.7306\n",
            "Epoch 18/25\n",
            "314/314 [==============================] - 271s 861ms/step - loss: 0.1604 - accuracy: 0.7552 - val_loss: 0.1552 - val_accuracy: 0.7202\n",
            "Epoch 19/25\n",
            "314/314 [==============================] - 268s 852ms/step - loss: 0.1579 - accuracy: 0.7582 - val_loss: 0.1518 - val_accuracy: 0.7772\n",
            "Epoch 20/25\n",
            "314/314 [==============================] - 270s 858ms/step - loss: 0.1575 - accuracy: 0.7573 - val_loss: 0.1851 - val_accuracy: 0.7098\n",
            "Epoch 21/25\n",
            "314/314 [==============================] - 271s 862ms/step - loss: 0.1545 - accuracy: 0.7651 - val_loss: 0.1547 - val_accuracy: 0.7358\n",
            "Epoch 22/25\n",
            "314/314 [==============================] - 273s 870ms/step - loss: 0.1516 - accuracy: 0.7694 - val_loss: 0.1481 - val_accuracy: 0.7668\n",
            "Epoch 23/25\n",
            "314/314 [==============================] - 274s 872ms/step - loss: 0.1500 - accuracy: 0.7738 - val_loss: 0.1571 - val_accuracy: 0.7254\n",
            "Epoch 24/25\n",
            "314/314 [==============================] - 269s 856ms/step - loss: 0.1492 - accuracy: 0.7740 - val_loss: 0.1485 - val_accuracy: 0.7461\n",
            "Epoch 25/25\n",
            "314/314 [==============================] - 268s 853ms/step - loss: 0.1471 - accuracy: 0.7750 - val_loss: 0.1645 - val_accuracy: 0.7668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1df36e59d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FajUAidsY-lU"
      },
      "source": [
        "Predição de uma imagem, baseado no modelo desenvolvido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlhEJwjMBEel"
      },
      "source": [
        "dir = '/content/drive/My Drive/TEES/Trabalho/ISIC2018_Task3_Test_Images/'\n",
        "result = np.zeros((2000, 7))\n",
        "j = 0\n",
        "for i in os.listdir(dir):\n",
        "  test_image = image.load_img(dir+i, target_size = (255, 255))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "  result[j] = cnn.predict(test_image)\n",
        "  j += 1\n",
        "  data_val.class_indices\n",
        "  if result[j][0] == 1:\n",
        "    print('Actinic keratoses and intraepithelial carcinoma(sun burn - Benign)')\n",
        "  elif result[j][1] == 1:\n",
        "    print('Basal Cell Carcinoma (Malign)')\n",
        "  elif result[j][2] == 1:\n",
        "    print('Benign Keratosis-like Lesions (Benign)')\n",
        "  elif result[j][3] == 1:\n",
        "    print('Dermatofibroma (Benign)')\n",
        "  elif result[j][4] == 1:\n",
        "    print('Melanoma (Malign)')\n",
        "  elif result[j][5] == 1:\n",
        "    print('Melanocytic Nevi (Benign)')\n",
        "  elif result[j][6] == 1:\n",
        "    print('Vascular Lesions (Benign)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh0lOUwsaOQS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "TdF54qRRaREw",
        "outputId": "21976dba-9e6d-4eac-c18c-f5c0db3315e5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3eae29180cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'requirements' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEC5Cq6Qaubo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}